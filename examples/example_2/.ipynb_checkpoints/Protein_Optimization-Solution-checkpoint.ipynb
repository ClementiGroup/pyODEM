{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyFExD Proteins\n",
    "\n",
    "This Notebook will help guide you through fitting the epsilon parameters of a protein structure based model using the new pyfexd package. Unlike previous packages, we no longer attempt to automate everything. Instead, we automate the parts that do the \"heavy lifting\" (computing optimal epsilons) while allowing the automation for the more lighter things (directory search) to be handeled by the end user. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, let's get the basic imports done. Then we'll define a few keyword packages for easy access of the key methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generic Packages\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "import mdtraj as md\n",
    "import shutil\n",
    "import ConfigParser\n",
    "\n",
    "#In house packages\n",
    "import model_builder as mdb\n",
    "import pyfexd\n",
    "\n",
    "#Shortcuts\n",
    "ml = pyfexd.model_loaders\n",
    "observables = pyfexd.observables\n",
    "ene = pyfexd.estimators.max_likelihood_estimate\n",
    "\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all the packages and names are loaded and defined, lets start making objects to prepare for optimization. The first step is to make a `Protein` object, which is a subclass of `Model`. A `Model` object is needed primarily for:\n",
    "\n",
    "1. Loading data from input files (traj.xtc).\n",
    "2. Generating Hamiltonian(epsilon) functions.\n",
    "\n",
    "Each `Model` subclass is customized for a particular use case. In this case, `Protein` refers to a case where we use the `model_builder` package, as well as when the Hamiltonian is linear in the epsilons.\n",
    "\n",
    "The `Model` object will be passed to the solver later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model according to 5PTI_cacb.ini.ini\n",
      "Options not shown default to None\n",
      "Model options:\n",
      "  topology             = 5PTI_cacb.pdb\n",
      "  bead_repr            = CACB\n",
      "  disulfides           = [5, 55, 14, 38, 30, 51]\n",
      "  pairwise_params_file = pairwise_params\n",
      "  model_params_file    = model_params\n",
      "  cb_volume            = flavored\n",
      "  contact_type         = Gaussian\n",
      "  using_sbm_gmx        = True\n",
      "\n",
      "Fitting options:\n",
      "  fret_pairs           = 17 42 30 65\n",
      "  iteration            = 0\n",
      "  t_fit                = 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jchen/code/model_builder/models/potentials/util.py:7: UserWarning: Using default SBM parameters\n",
      "  warnings.warn(\"Using default SBM parameters\")\n",
      "/home/jchen/code/model_builder/models/potentials/util.py:10: UserWarning: Using default SBM parameters\n",
      "  warnings.warn(\"Using default SBM parameters\")\n"
     ]
    }
   ],
   "source": [
    "model_name = \"5PTI_cacb.ini\"\n",
    "pmodel = ml.Protein(model_name)\n",
    "pmodel.set_temperature(70)\n",
    "iteration = pmodel.fittingopts[\"iteration\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that's done, let's generate an `ExperimentalObservables` object. This object is meant to hold all the observed experimental data. For our particular example, we want to load a histogram data file. To do so, we will create the object and then add the experimental data using `add_histogram()`. In the future, different data types will be implemented as `add_X`. Some useful hints:\n",
    "\n",
    "1. The first argument is always the experimetal data .dat file.\n",
    "2. `errortype` specifies the probability distribution. WARNING: Not implemented for anything other than gaussians yet.\n",
    "3. `scale` specifies how much to scale the standard deviation by. This does not affect the final result other than scaling the final value of Q that is calculated. The Optimal minima will not change with scaling.\n",
    "\n",
    "The format of the experimental data in the .dat file is simple. The first column gives the value of some observable and the second column gives its standard deviation. Right now, all observables are assumed to follow a gaussian random distribution, but different distributions can be added in the code in the future. Furthermore, you must also give each `add_X` command enough information to construct the observation from a simulation. For a histogram, this can be the edges of each bin, or the range and number of bins, or a spacing and range. For our example, we use the edges of each bin. I have found this to be the most robust for reproducing the same observable as the edges used in histogramming a data set are directly outputted form numpy's histogram command.\n",
    "\n",
    "The `ExperimentalObservables` will be passed to the solver later. It contains the means of computing the observables from a simulation, automatically formatted internally, as well as computing the Q value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "obs = observables.ExperimentalObservables() #initialize object\n",
    "edges = np.loadtxt(\"edges.dat\")\n",
    "obs.add_histogram(\"exp_data.dat\", edges=edges, errortype=\"gaussian\", scale=1000.0) #load and format the data distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With everything loaded, the next thing to do would be to load load the traj.xtc file. Like I said, we have to specify the location of these files for loading, but the loaded values will be formatted for later use automatically. All `Model` objects have a `load_data()` command that can extract the data set from some file format.\n",
    "\n",
    "Furthermore, we need to extract the data for the observable. This is not yet implemented to happen automatically, but for a histogram it's simple. We just want the distance between two atoms on the FRET coordinate. This too will be passed as a list, where each entry corresponds to data for each type of observable loaded. For our case, it's a simple 1-entry list.\n",
    "\n",
    "The loaded data (`data`) as well as the experimental data (`exp_data`) will be passed to the solver later as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model data\n",
    "directory = \"%s/iteration_%d\" % (cwd,iteration)\n",
    "os.chdir(directory)\n",
    "data = pmodel.load_data(\"traj.xtc\")\n",
    "\n",
    "#experimental data\n",
    "traj = md.load(\"traj.xtc\", top=\"conf.gro\")\n",
    "dist = md.compute_distances(traj, [[29,64]], periodic=False)[:,0]\n",
    "exp_data = [dist]\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, we need to discretize the data into bins as well as compute the initial equilibrium distribution. This too is yet automated as there are many unique ways of doing so. Just to name a few:\n",
    "\n",
    "1. You can simply pick a coordinate and discretize along there (such as the FRET distance on a histogram, or number of native contacts formed)\n",
    "2. You can compute TICA and a Markove State Model using the pyEMMA package. \n",
    "3. You can use TRAM (pyEMMA) and combine many data sets.\n",
    "\n",
    "For now, let's do a simple discretization into 20 bins along the FRET coordinate and use that to compute th equilibrium distribution. With a good cordinate, this should work well. The `equilibrium_frames` is a list where each entry is a list of indices corresponding to the frames inside that equilibrium state. The solver will then automatically compute the stationary distribution from this data set. It can be overrided passing the `stationary_distributions` kwarg to the solver.\n",
    "\n",
    "The `equilibrium_frames` will be passed to the solver later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist, tempedges, slices = stats.binned_statistic(dist, np.ones(np.shape(data)[0]), statistic=\"sum\",bins=20)\n",
    "possible_slices = np.arange(np.min(slices), np.max(slices)+1)\n",
    "equilibrium_frames = []\n",
    "indices = np.arange(np.shape(data)[0])\n",
    "for i in range(np.max(slices)+1):\n",
    "    state_data = indices[slices == i]\n",
    "    if not state_data.size == 0:\n",
    "        equilibrium_frames.append(state_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not a necessary step, but a very good idea. One of the things that can go wrong in an optimization step is if the values of the epsilons reach unphysical values. For example, there's no way an epsilons should have a value of 5. In order to prevent this, we can pass an ordered list, where each entry gives a list with a lower bound and upper bound for  that epsilon. For us, let's keep a pretty tight restriction to avoid overfitting on the initial step. Let's make it so the epsilons can't change by +/-0.5 and no epsilon value may exceed 3 or go under 0. These extra things go into the `function_args` variable as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bounds = []\n",
    "for i in range(np.shape(pmodel.epsilons)[0]):\n",
    "    lower_bound = pmodel.epsilons[i] - 0.5\n",
    "    if lower_bound < 0:\n",
    "        lower_bound = 0\n",
    "    upper_bound = pmodel.epsilons[i] + 0.5\n",
    "    if upper_bound > 3:\n",
    "        upper_bound = 3\n",
    "    bounds.append([lower_bound,upper_bound])\n",
    "    \n",
    "function_args = {\"bounds\":bounds}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, all the preliminaries are set up. We can run the whole thing now, and output the new Q value to see how much things have improved. When running the solver, you get a `estimators_class` as output, here it's called `solutions`. Many values exist internally such as the new and old epsilons, the new and old Q values and some useful metrics such as how many times functions were called and how long each step took. \n",
    "\n",
    "Metrics you can currently view are:\n",
    "1. `count_hepsilon`: Number of times a Hamiltonian was computed. \n",
    "2. `count_dhepsilon`: Number of times the derivative of the Hamiltonian was computed.\n",
    "3. `count_Qcalls`: Number of times the Q function was computed. Nominally the number of steps in parameter space.\n",
    "\n",
    "You will notice the counts for the Hamiltonian are multiplied by the number of equilibrium frames. This is because each equilibrium state has its own Hamiltonian to compute. After normalizing those counts, they all agree except for the extra two instances of calling the Hamiltonian. These instances occur when it saves the values internally, it recomputes the Hamiltonian values.\n",
    "\n",
    "A note on solvers. Many algorithms for optmization have been implemented. Most of them are wrappers for scipy functions. Currently, the most stable one for proteins that has been extensively used and tested is bfgs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing EstimatorsObject\n",
      "Initializaiton Completed: 0.055316 Minutes\n",
      "Starting Optimization\n",
      "Optimization Complete: 0.585202 minutes\n",
      "Total hepsilon calls: 250\n",
      "Total dhepsilon calls: 248\n",
      "Total Q calls: 248\n",
      "\n",
      "Q Functions:\n",
      "Qold: -0.00428745\n",
      "Qnew: -0.0813663\n",
      "\n",
      "Log Q Functions:\n",
      "Qold: 5.45206\n",
      "Qnew: 2.50879\n",
      "Epsilons are: \n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[ 1.47458283  1.08821154  1.30102241  0.50875884  0.59753067  1.49457489\n",
      "  0.99275961  0.76061147  1.49978634  0.60674385  1.07241168  0.50008034\n",
      "  0.5008859   0.9981017   0.8331971   0.50010548  0.56110314  0.57356191\n",
      "  1.47088537  1.49953834  1.49874626  0.96133636  0.50325466  0.56228197\n",
      "  1.48547899  1.15430176  0.50094395  1.01688266  0.57799927  0.5000611\n",
      "  1.49995309  1.40015562  0.50101939  0.62838849  0.66343116  0.50982576\n",
      "  0.50529435  0.5015678   1.45751994  0.76981217  0.50008095  0.87836203\n",
      "  0.97879092  0.5798356   0.96121878  0.50003852  1.04417806  0.50927415\n",
      "  0.50326987  0.55582016  1.29322329  1.49686649  0.50001984  0.50019342\n",
      "  0.50073464  0.50083941  0.5         0.50105656  0.50021443  0.50024026\n",
      "  0.82441315  1.46217241  1.16193175  1.42496732  1.45742027  0.50109577\n",
      "  0.5364474   0.5         0.52713845  0.5011615   0.50105488  0.53764618\n",
      "  0.72664418  0.50004801  0.5081563   1.2050335   1.0163697   1.4779248\n",
      "  0.76192641  1.11722079  1.25123406  1.49974586  1.06253314  0.91640431\n",
      "  1.49792242  0.50136562  1.49993274  1.49224345  0.98298206  1.49999141\n",
      "  0.7303313   1.10412583  0.72759071  0.56820161  0.98742859  0.57919977\n",
      "  1.49115904  0.50001922  0.50082907  0.52663303  0.97910753  1.35732716\n",
      "  0.50010381  0.50065517  0.82608148  1.49966134  1.49833605  0.50047923\n",
      "  1.49818818  1.49422849  0.91032043  0.86659511  1.49778536  1.02929883\n",
      "  1.49962438  0.83576123  0.50052734  1.02938351  1.43538491  0.85988575\n",
      "  1.38872168  0.50190558  0.87619019  0.55732405  0.50007179  0.71871741\n",
      "  0.55007207  1.09559618  1.46894047  1.15251896  1.05540743  1.12495032\n",
      "  0.94515958  0.5170704   0.5014369   1.49998873  1.49867458  0.54468821\n",
      "  1.49994857  1.18330721  1.49912489  1.49999625  1.11534854  1.49999749\n",
      "  1.30280497  1.38246045  1.05214411]\n"
     ]
    }
   ],
   "source": [
    "solutions = ene(data, equilibrium_frames, obs, pmodel, obs_data=exp_data, solver=\"bfgs\", logq=True, kwargs=function_args)\n",
    "\n",
    "print \"Total hepsilon calls: %d\" % (solutions.count_hepsilon / solutions.number_equilibrium_states)\n",
    "print \"Total dhepsilon calls: %d\" % (solutions.count_dhepsilon / solutions.number_equilibrium_states)\n",
    "print \"Total Q calls: %d\" % (solutions.count_Qcalls)\n",
    "\n",
    "new_eps = solutions.new_epsilons\n",
    "old_eps = solutions.old_epsilons\n",
    "Qold = solutions.oldQ\n",
    "Qnew = solutions.newQ\n",
    "Qfunction = solutions.log_Qfunction_epsilon\n",
    "\n",
    "print\n",
    "print \"Q Functions:\"\n",
    "print \"Qold: %g\" %Qold\n",
    "print \"Qnew: %g\" %Qnew\n",
    "\n",
    "print\n",
    "print \"Log Q Functions:\"\n",
    "print \"Qold: %g\" %Qfunction(old_eps)\n",
    "print \"Qnew: %g\" %Qfunction(new_eps)\n",
    "\n",
    "print \"Epsilons are: \"\n",
    "print old_eps\n",
    "print new_eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all of this done, now, we just need to save all the files and modify the .ini file so that it knows where the new information is. How you do this exactly is up to you. But some code to help you along is shown below. The first block will make a new directory called newton in the direcotry of the current iteration and then save a copy of model_params and pairwise_params. The second block will modify the appropriate parameters in the .ini file according to this save scheme. Simply comment out the `save_model()` command when ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_dir = \"%s/newton\" % directory \n",
    "if not os.path.isdir(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "    \n",
    "with open(\"%s/model_params\"%save_dir, \"w\") as mparamsfil:\n",
    "    mparamsfil.write(\"# model parameters\\n\")\n",
    "    for i in new_eps:\n",
    "        mparamsfil.write(\"%5.3f\\n\" % i)\n",
    "shutil.copy(\"%s/pairwise_params\" % cwd, \"%s/pairwise_params\"%save_dir)\n",
    "\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_model(inifile, newiter, newfile_location):\n",
    "    config = ConfigParser.SafeConfigParser(allow_no_value=True)\n",
    "    config.read(inifile)\n",
    "    \n",
    "    config.set(\"fitting\", \"iteration\", str(newiter))\n",
    "    newparams = \"%s/model_params\" % newfile_location\n",
    "    newpairwise = \"%s/pairwise_params\" % newfile_location\n",
    "    \n",
    "    config.set(\"model\", \"pairwise_params_file\", newpairwise) \n",
    "    config.set(\"model\", \"model_params_file\", newparams)\n",
    "\n",
    "    \n",
    "\n",
    "    shutil.move(inifile,\"1.%s\" %inifile)\n",
    "\n",
    "    with open(inifile,\"w\") as cfgfile:\n",
    "        config.write(cfgfile)\n",
    "\n",
    "\n",
    "#save_model(model_name, iteration+1, \"iteration_%d/newton\" % iteration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
